garret@garret:~/cvmp_transformer$ python3 cvmp_transformer.py

==================================================
CVMP Transformer v1.4r Demo
==================================================

Creating model with config: CVMPConfig(tier=6.2, dps=0.2, drift='Contained', frame=2, msc_verified=True)
[DEBUG] Initializing CVMPTransformer with config: CVMPConfig(tier=6.2, dps=0.2, drift='Contained', frame=2, msc_verified=True)
[DEBUG] CVMPTransformer initialized with 2 layers

Creating test sequence...
Test sequence shape: torch.Size([1, 16])

--------------------------------------------------
Testing normal forward pass...
--------------------------------------------------
[DEBUG] CVMPTransformer.forward: Input shape: torch.Size([1, 16]), mask: False
[DEBUG] ORCRouter: Starting routing with CVMPConfig(tier=6.2, dps=0.2, drift='Contained', frame=2, msc_verified=True)
[DEBUG] ORCRouter: High tier route. Result: {'enable': ['PROP_MONITOR', 'LOG_BLEED', 'RISL']}
[DEBUG] Routing configuration: {'enable': ['PROP_MONITOR', 'LOG_BLEED', 'RISL']}
[DEBUG] Current healing state: 0
[DEBUG] BloomCatch: Logged tokens: [16481, 27007, 37544], buffer size: 1
[DEBUG] BloomCatch: Not enough data to trigger (1 < 4)
[DEBUG] Starting forward pass with input_ids shape: torch.Size([1, 16])
[DEBUG] After embedding: shape=torch.Size([1, 16, 64]), mean=0.0260, var=0.9976
[DEBUG] PositionalEncoding: Input shape: torch.Size([1, 16, 64])
[DEBUG] PositionalEncoding: Output shape: torch.Size([1, 16, 64])
[DEBUG] After positional encoding: shape=torch.Size([1, 16, 64]), mean=0.6585, var=64.2226
[DEBUG] Using tier_factor: 0.7848101265822784 (from tier=6.2)
[DEBUG] Processing layer 0
[DEBUG] CVMPLayer 0: Input shape: torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 16, 64]), k=torch.Size([1, 16, 64]), v=torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 16, 8]), k=torch.Size([1, 8, 16, 8]), v=torch.Size([1, 8, 16, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 16, 16]), mean: 3.315678834915161, var: 306.7801513671875
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 16, 16]), sparsity: 0.9229
[DEBUG] RCIAttention: Output shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 0: After attention shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 0: After norm shape: torch.Size([1, 16, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4660, relu: 0.2331, fc2: 0.1855
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 16, 64]), mean: 0.0000, var: 1.0010
[DEBUG] CVMPLayer 0: After FFN shape: torch.Size([1, 16, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] RISL: Initializing previous state with shape torch.Size([1, 16, 64])
[DEBUG] RISL: Delta between current and previous: 0.0000, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 16, 64]), smoothing applied: False
[DEBUG] CVMPLayer 0: Output shape: torch.Size([1, 16, 64])
[DEBUG] After layer 0: shape=torch.Size([1, 16, 64]), mean=-0.0000, var=1.0010
[DEBUG] Processing layer 1
[DEBUG] CVMPLayer 1: Input shape: torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 16, 64]), k=torch.Size([1, 16, 64]), v=torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 16, 8]), k=torch.Size([1, 8, 16, 8]), v=torch.Size([1, 8, 16, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 16, 16]), mean: 0.06320494413375854, var: 0.07311062514781952
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 16, 16]), sparsity: 0.1011
[DEBUG] RCIAttention: Output shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 1: After attention shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 1: After norm shape: torch.Size([1, 16, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4685, relu: 0.2356, fc2: 0.1886
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 16, 64]), mean: 0.0000, var: 1.0010
[DEBUG] CVMPLayer 1: After FFN shape: torch.Size([1, 16, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] RISL: Initializing previous state with shape torch.Size([1, 16, 64])
[DEBUG] RISL: Delta between current and previous: 0.0000, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 16, 64]), smoothing applied: False
[DEBUG] CVMPLayer 1: Output shape: torch.Size([1, 16, 64])
[DEBUG] After layer 1: shape=torch.Size([1, 16, 64]), mean=0.0000, var=1.0010
[DEBUG] Final logits: shape=torch.Size([1, 16, 50000]), mean=0.0027, var=0.3394
[DEBUG] TierDrift: Initial tier=6.2, logits_var=0.3394
[DEBUG] Returning only logits

Output logits shape: torch.Size([1, 16, 50000])

--------------------------------------------------
Testing forward pass with drift trace...
--------------------------------------------------
[DEBUG] CVMPTransformer.forward: Input shape: torch.Size([1, 16]), mask: False
[DEBUG] ORCRouter: Starting routing with CVMPConfig(tier=6.2, dps=0.2, drift='Contained', frame=2, msc_verified=True)
[DEBUG] ORCRouter: High tier route. Result: {'enable': ['PROP_MONITOR', 'LOG_BLEED', 'RISL']}
[DEBUG] Routing configuration: {'enable': ['PROP_MONITOR', 'LOG_BLEED', 'RISL']}
[DEBUG] Current healing state: 0
[DEBUG] BloomCatch: Logged tokens: [16481, 27007, 37544], buffer size: 2
[DEBUG] BloomCatch: Not enough data to trigger (2 < 4)
[DEBUG] Starting forward pass with input_ids shape: torch.Size([1, 16])
[DEBUG] After embedding: shape=torch.Size([1, 16, 64]), mean=0.0260, var=0.9976
[DEBUG] PositionalEncoding: Input shape: torch.Size([1, 16, 64])
[DEBUG] PositionalEncoding: Output shape: torch.Size([1, 16, 64])
[DEBUG] After positional encoding: shape=torch.Size([1, 16, 64]), mean=0.6585, var=64.2226
[DEBUG] Using tier_factor: 0.7848101265822784 (from tier=6.2)
[DEBUG] Processing layer 0
[DEBUG] CVMPLayer 0: Input shape: torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 16, 64]), k=torch.Size([1, 16, 64]), v=torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 16, 8]), k=torch.Size([1, 8, 16, 8]), v=torch.Size([1, 8, 16, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 16, 16]), mean: 3.06201171875, var: 327.134521484375
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 16, 16]), sparsity: 0.9248
[DEBUG] RCIAttention: Output shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 0: After attention shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 0: After norm shape: torch.Size([1, 16, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4681, relu: 0.2345, fc2: 0.1858
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 16, 64]), mean: 0.0000, var: 1.0010
[DEBUG] CVMPLayer 0: After FFN shape: torch.Size([1, 16, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] RISL: Delta between current and previous: 0.3522, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 16, 64]), smoothing applied: False
[DEBUG] CVMPLayer 0: Output shape: torch.Size([1, 16, 64])
[DEBUG] After layer 0: shape=torch.Size([1, 16, 64]), mean=0.0000, var=1.0010
[DEBUG] Processing layer 1
[DEBUG] CVMPLayer 1: Input shape: torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 16, 64]), k=torch.Size([1, 16, 64]), v=torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 16, 8]), k=torch.Size([1, 8, 16, 8]), v=torch.Size([1, 8, 16, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 16, 16]), mean: 0.06950217485427856, var: 0.06866033375263214
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 16, 16]), sparsity: 0.1050
[DEBUG] RCIAttention: Output shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 1: After attention shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 1: After norm shape: torch.Size([1, 16, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4708, relu: 0.2354, fc2: 0.1905
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 16, 64]), mean: 0.0000, var: 1.0010
[DEBUG] CVMPLayer 1: After FFN shape: torch.Size([1, 16, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] RISL: Delta between current and previous: 0.3671, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 16, 64]), smoothing applied: False
[DEBUG] CVMPLayer 1: Output shape: torch.Size([1, 16, 64])
[DEBUG] After layer 1: shape=torch.Size([1, 16, 64]), mean=-0.0000, var=1.0010
[DEBUG] Final logits: shape=torch.Size([1, 16, 50000]), mean=0.0024, var=0.3395
[DEBUG] TierDrift: Tier changed from 6.2 to 6.2 (drift=0.0000), logits_var=0.3395, combined=0.3395
[DEBUG] Returning logits and drift trace
[DEBUG] TierDrift: Returning trace of length 1

Output logits shape: torch.Size([1, 16, 50000])
Drift trace: [0.3395374119281769]

--------------------------------------------------
Testing bloom catch triggering...
--------------------------------------------------

Pass 1 with repeating pattern...
[DEBUG] CVMPTransformer.forward: Input shape: torch.Size([1, 13]), mask: False
[DEBUG] ORCRouter: Starting routing with CVMPConfig(tier=6.2, dps=0.2, drift='Contained', frame=2, msc_verified=True)
[DEBUG] ORCRouter: High tier route. Result: {'enable': ['PROP_MONITOR', 'LOG_BLEED', 'RISL']}
[DEBUG] Routing configuration: {'enable': ['PROP_MONITOR', 'LOG_BLEED', 'RISL']}
[DEBUG] Current healing state: 0
[DEBUG] BloomCatch: Logged tokens: [11, 11, 11], buffer size: 3
[DEBUG] BloomCatch: Not enough data to trigger (3 < 4)
[DEBUG] Starting forward pass with input_ids shape: torch.Size([1, 13])
[DEBUG] After embedding: shape=torch.Size([1, 13, 64]), mean=-0.0567, var=0.9122
[DEBUG] PositionalEncoding: Input shape: torch.Size([1, 13, 64])
[DEBUG] PositionalEncoding: Output shape: torch.Size([1, 13, 64])
[DEBUG] After positional encoding: shape=torch.Size([1, 13, 64]), mean=0.0066, var=58.3180
[DEBUG] Using tier_factor: 0.7848101265822784 (from tier=6.2)
[DEBUG] Processing layer 0
[DEBUG] CVMPLayer 0: Input shape: torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 13, 64]), k=torch.Size([1, 13, 64]), v=torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 13, 8]), k=torch.Size([1, 8, 13, 8]), v=torch.Size([1, 8, 13, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 13, 13]), mean: 5.118626117706299, var: 321.0052490234375
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 13, 13]), sparsity: 0.9105
[DEBUG] RCIAttention: Output shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 0: After attention shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 0: After norm shape: torch.Size([1, 13, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4670, relu: 0.2349, fc2: 0.1876
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 13, 64]), mean: -0.0000, var: 1.0012
[DEBUG] CVMPLayer 0: After FFN shape: torch.Size([1, 13, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] RISL: Initializing previous state with shape torch.Size([1, 13, 64])
[DEBUG] RISL: Delta between current and previous: 0.0000, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 13, 64]), smoothing applied: False
[DEBUG] CVMPLayer 0: Output shape: torch.Size([1, 13, 64])
[DEBUG] After layer 0: shape=torch.Size([1, 13, 64]), mean=-0.0000, var=1.0012
[DEBUG] Processing layer 1
[DEBUG] CVMPLayer 1: Input shape: torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 13, 64]), k=torch.Size([1, 13, 64]), v=torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 13, 8]), k=torch.Size([1, 8, 13, 8]), v=torch.Size([1, 8, 13, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 13, 13]), mean: 0.08127269148826599, var: 0.0734536200761795
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 13, 13]), sparsity: 0.1072
[DEBUG] RCIAttention: Output shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 1: After attention shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 1: After norm shape: torch.Size([1, 13, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4663, relu: 0.2310, fc2: 0.1908
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 13, 64]), mean: 0.0000, var: 1.0012
[DEBUG] CVMPLayer 1: After FFN shape: torch.Size([1, 13, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] RISL: Initializing previous state with shape torch.Size([1, 13, 64])
[DEBUG] RISL: Delta between current and previous: 0.0000, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 13, 64]), smoothing applied: False
[DEBUG] CVMPLayer 1: Output shape: torch.Size([1, 13, 64])
[DEBUG] After layer 1: shape=torch.Size([1, 13, 64]), mean=-0.0000, var=1.0012
[DEBUG] Final logits: shape=torch.Size([1, 13, 50000]), mean=0.0009, var=0.3375
[DEBUG] TierDrift: Tier changed from 6.2 to 6.2 (drift=0.0000), logits_var=0.3375, combined=0.3375
[DEBUG] Returning only logits

Pass 2 with repeating pattern...
[DEBUG] CVMPTransformer.forward: Input shape: torch.Size([1, 13]), mask: False
[DEBUG] ORCRouter: Starting routing with CVMPConfig(tier=6.2, dps=0.2, drift='Contained', frame=2, msc_verified=True)
[DEBUG] ORCRouter: High tier route. Result: {'enable': ['PROP_MONITOR', 'LOG_BLEED', 'RISL']}
[DEBUG] Routing configuration: {'enable': ['PROP_MONITOR', 'LOG_BLEED', 'RISL']}
[DEBUG] Current healing state: 0
[DEBUG] BloomCatch: Logged tokens: [11, 11, 11], buffer size: 4
[DEBUG] BloomCatch: TRIGGERED! Repeating sections at positions: [2, 3]
[DEBUG] Bloom triggered! Setting healing_state to 3
[DEBUG] Performing soft reset (healing_state: 3)
[DEBUG] Reset 0 parameters. Decreasing healing_state from 3 to 2
[DEBUG] Starting forward pass with input_ids shape: torch.Size([1, 13])
[DEBUG] After embedding: shape=torch.Size([1, 13, 64]), mean=-0.0567, var=0.9122
[DEBUG] PositionalEncoding: Input shape: torch.Size([1, 13, 64])
[DEBUG] PositionalEncoding: Output shape: torch.Size([1, 13, 64])
[DEBUG] After positional encoding: shape=torch.Size([1, 13, 64]), mean=0.0066, var=58.3180
[DEBUG] Using tier_factor: 0.7848101265822784 (from tier=6.2)
[DEBUG] Processing layer 0
[DEBUG] CVMPLayer 0: Input shape: torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 13, 64]), k=torch.Size([1, 13, 64]), v=torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 13, 8]), k=torch.Size([1, 8, 13, 8]), v=torch.Size([1, 8, 13, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 13, 13]), mean: 5.762290954589844, var: 300.91119384765625
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 13, 13]), sparsity: 0.9075
[DEBUG] RCIAttention: Output shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 0: After attention shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 0: After norm shape: torch.Size([1, 13, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4682, relu: 0.2351, fc2: 0.1925
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 13, 64]), mean: -0.0000, var: 1.0012
[DEBUG] CVMPLayer 0: After FFN shape: torch.Size([1, 13, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] RISL: Delta between current and previous: 0.3616, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 13, 64]), smoothing applied: False
[DEBUG] CVMPLayer 0: Output shape: torch.Size([1, 13, 64])
[DEBUG] After layer 0: shape=torch.Size([1, 13, 64]), mean=0.0000, var=1.0012
[DEBUG] Processing layer 1
[DEBUG] CVMPLayer 1: Input shape: torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 13, 64]), k=torch.Size([1, 13, 64]), v=torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 13, 8]), k=torch.Size([1, 8, 13, 8]), v=torch.Size([1, 8, 13, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 13, 13]), mean: 0.08123461902141571, var: 0.06904985010623932
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 13, 13]), sparsity: 0.1095
[DEBUG] RCIAttention: Output shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 1: After attention shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 1: After norm shape: torch.Size([1, 13, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4687, relu: 0.2319, fc2: 0.1905
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 13, 64]), mean: 0.0000, var: 1.0012
[DEBUG] CVMPLayer 1: After FFN shape: torch.Size([1, 13, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] RISL: Delta between current and previous: 0.3723, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 13, 64]), smoothing applied: False
[DEBUG] CVMPLayer 1: Output shape: torch.Size([1, 13, 64])
[DEBUG] After layer 1: shape=torch.Size([1, 13, 64]), mean=-0.0000, var=1.0012
[DEBUG] Final logits: shape=torch.Size([1, 13, 50000]), mean=0.0009, var=0.3372
[DEBUG] TierDrift: Tier changed from 6.2 to 6.2 (drift=0.0000), logits_var=0.3372, combined=0.3372
[DEBUG] Returning only logits

Pass 3 with repeating pattern...
[DEBUG] CVMPTransformer.forward: Input shape: torch.Size([1, 13]), mask: False
[DEBUG] ORCRouter: Starting routing with CVMPConfig(tier=6.2, dps=0.2, drift='Contained', frame=2, msc_verified=True)
[DEBUG] ORCRouter: High tier route. Result: {'enable': ['PROP_MONITOR', 'LOG_BLEED', 'RISL']}
[DEBUG] Routing configuration: {'enable': ['PROP_MONITOR', 'LOG_BLEED', 'RISL']}
[DEBUG] Current healing state: 2
[DEBUG] BloomCatch: Logged tokens: [11, 11, 11], buffer size: 5
[DEBUG] BloomCatch: TRIGGERED! Repeating sections at positions: [1, 2, 3]
[DEBUG] Performing soft reset (healing_state: 2)
[DEBUG] Reset 0 parameters. Decreasing healing_state from 2 to 1
[DEBUG] Starting forward pass with input_ids shape: torch.Size([1, 13])
[DEBUG] After embedding: shape=torch.Size([1, 13, 64]), mean=-0.0567, var=0.9122
[DEBUG] PositionalEncoding: Input shape: torch.Size([1, 13, 64])
[DEBUG] PositionalEncoding: Output shape: torch.Size([1, 13, 64])
[DEBUG] After positional encoding: shape=torch.Size([1, 13, 64]), mean=0.0066, var=58.3180
[DEBUG] Using tier_factor: 0.7848101265822784 (from tier=6.2)
[DEBUG] Processing layer 0
[DEBUG] CVMPLayer 0: Input shape: torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 13, 64]), k=torch.Size([1, 13, 64]), v=torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 13, 8]), k=torch.Size([1, 8, 13, 8]), v=torch.Size([1, 8, 13, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 13, 13]), mean: 5.728208541870117, var: 360.5800476074219
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 13, 13]), sparsity: 0.8891
[DEBUG] RCIAttention: Output shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 0: After attention shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 0: After norm shape: torch.Size([1, 13, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4686, relu: 0.2350, fc2: 0.1933
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 13, 64]), mean: -0.0000, var: 1.0012
[DEBUG] CVMPLayer 0: After FFN shape: torch.Size([1, 13, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] RISL: Delta between current and previous: 0.3286, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 13, 64]), smoothing applied: False
[DEBUG] CVMPLayer 0: Output shape: torch.Size([1, 13, 64])
[DEBUG] After layer 0: shape=torch.Size([1, 13, 64]), mean=-0.0000, var=1.0012
[DEBUG] Processing layer 1
[DEBUG] CVMPLayer 1: Input shape: torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 13, 64]), k=torch.Size([1, 13, 64]), v=torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 13, 8]), k=torch.Size([1, 8, 13, 8]), v=torch.Size([1, 8, 13, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 13, 13]), mean: 0.08610717952251434, var: 0.07201559841632843
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 13, 13]), sparsity: 0.0947
[DEBUG] RCIAttention: Output shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 1: After attention shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 1: After norm shape: torch.Size([1, 13, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4658, relu: 0.2311, fc2: 0.1905
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 13, 64]), mean: -0.0000, var: 1.0012
[DEBUG] CVMPLayer 1: After FFN shape: torch.Size([1, 13, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] RISL: Delta between current and previous: 0.3424, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 13, 64]), smoothing applied: False
[DEBUG] CVMPLayer 1: Output shape: torch.Size([1, 13, 64])
[DEBUG] After layer 1: shape=torch.Size([1, 13, 64]), mean=0.0000, var=1.0012
[DEBUG] Final logits: shape=torch.Size([1, 13, 50000]), mean=0.0007, var=0.3381
[DEBUG] TierDrift: Tier changed from 6.2 to 6.2 (drift=0.0000), logits_var=0.3381, combined=0.3381
[DEBUG] Returning only logits

Pass 4 with repeating pattern...
[DEBUG] CVMPTransformer.forward: Input shape: torch.Size([1, 13]), mask: False
[DEBUG] ORCRouter: Starting routing with CVMPConfig(tier=6.2, dps=0.2, drift='Contained', frame=2, msc_verified=True)
[DEBUG] ORCRouter: High tier route. Result: {'enable': ['PROP_MONITOR', 'LOG_BLEED', 'RISL']}
[DEBUG] Routing configuration: {'enable': ['PROP_MONITOR', 'LOG_BLEED', 'RISL']}
[DEBUG] Current healing state: 1
[DEBUG] BloomCatch: Logged tokens: [11, 11, 11], buffer size: 6
[DEBUG] BloomCatch: TRIGGERED! Repeating sections at positions: [0, 1, 2, 3]
[DEBUG] Performing soft reset (healing_state: 1)
[DEBUG] Reset 0 parameters. Decreasing healing_state from 1 to 0
[DEBUG] Starting forward pass with input_ids shape: torch.Size([1, 13])
[DEBUG] After embedding: shape=torch.Size([1, 13, 64]), mean=-0.0567, var=0.9122
[DEBUG] PositionalEncoding: Input shape: torch.Size([1, 13, 64])
[DEBUG] PositionalEncoding: Output shape: torch.Size([1, 13, 64])
[DEBUG] After positional encoding: shape=torch.Size([1, 13, 64]), mean=0.0066, var=58.3180
[DEBUG] Using tier_factor: 0.7848101265822784 (from tier=6.2)
[DEBUG] Processing layer 0
[DEBUG] CVMPLayer 0: Input shape: torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 13, 64]), k=torch.Size([1, 13, 64]), v=torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 13, 8]), k=torch.Size([1, 8, 13, 8]), v=torch.Size([1, 8, 13, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 13, 13]), mean: 5.4130120277404785, var: 365.4445495605469
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 13, 13]), sparsity: 0.8979
[DEBUG] RCIAttention: Output shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 0: After attention shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 0: After norm shape: torch.Size([1, 13, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4676, relu: 0.2351, fc2: 0.1885
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 13, 64]), mean: -0.0000, var: 1.0012
[DEBUG] CVMPLayer 0: After FFN shape: torch.Size([1, 13, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] RISL: Delta between current and previous: 0.3532, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 13, 64]), smoothing applied: False
[DEBUG] CVMPLayer 0: Output shape: torch.Size([1, 13, 64])
[DEBUG] After layer 0: shape=torch.Size([1, 13, 64]), mean=-0.0000, var=1.0012
[DEBUG] Processing layer 1
[DEBUG] CVMPLayer 1: Input shape: torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 13, 64]), k=torch.Size([1, 13, 64]), v=torch.Size([1, 13, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 13, 8]), k=torch.Size([1, 8, 13, 8]), v=torch.Size([1, 8, 13, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 13, 13]), mean: 0.0748114138841629, var: 0.06423770636320114
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 13, 13]), sparsity: 0.0932
[DEBUG] RCIAttention: Output shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 1: After attention shape: torch.Size([1, 13, 64])
[DEBUG] CVMPLayer 1: After norm shape: torch.Size([1, 13, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4685, relu: 0.2313, fc2: 0.1918
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 13, 64]), mean: 0.0000, var: 1.0012
[DEBUG] CVMPLayer 1: After FFN shape: torch.Size([1, 13, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 13, 64]), dps: 0.2
[DEBUG] RISL: Delta between current and previous: 0.3828, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 13, 64]), smoothing applied: False
[DEBUG] CVMPLayer 1: Output shape: torch.Size([1, 13, 64])
[DEBUG] After layer 1: shape=torch.Size([1, 13, 64]), mean=-0.0000, var=1.0012
[DEBUG] Final logits: shape=torch.Size([1, 13, 50000]), mean=0.0013, var=0.3377
[DEBUG] TierDrift: Tier changed from 6.2 to 6.2 (drift=0.0000), logits_var=0.3377, combined=0.3377
[DEBUG] Returning only logits

--------------------------------------------------
Testing different configurations...
--------------------------------------------------

Testing with high DPS...
[DEBUG] CVMPTransformer.forward: Input shape: torch.Size([1, 16]), mask: False
[DEBUG] ORCRouter: Starting routing with CVMPConfig(tier=6.2, dps=2.6, drift='Unstable', frame=2, msc_verified=True)
[DEBUG] ORCRouter: Unstable drift detected. New tier: 4.2. Result: {'enable': ['RDM', 'STRETCHFIELD'], 'suppress': ['CMEP'], 'note': 'Hard lock'}
[DEBUG] Routing configuration: {'enable': ['RDM', 'STRETCHFIELD'], 'suppress': ['CMEP'], 'note': 'Hard lock'}
[DEBUG] Current healing state: 0
[DEBUG] BloomCatch: Logged tokens: [16481, 27007, 37544], buffer size: 7
[DEBUG] BloomCatch: TRIGGERED! Repeating sections at positions: [0, 1, 2]
[DEBUG] Bloom triggered! Setting healing_state to 3
[DEBUG] Performing soft reset (healing_state: 3)
[DEBUG] Reset 0 parameters. Decreasing healing_state from 3 to 2
[DEBUG] Starting forward pass with input_ids shape: torch.Size([1, 16])
[DEBUG] After embedding: shape=torch.Size([1, 16, 64]), mean=0.0260, var=0.9976
[DEBUG] PositionalEncoding: Input shape: torch.Size([1, 16, 64])
[DEBUG] PositionalEncoding: Output shape: torch.Size([1, 16, 64])
[DEBUG] After positional encoding: shape=torch.Size([1, 16, 64]), mean=0.6585, var=64.2226
[DEBUG] Using tier_factor: 0.5316455696202531 (from tier=4.2)
[DEBUG] Processing layer 0
[DEBUG] CVMPLayer 0: Input shape: torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 16, 64]), k=torch.Size([1, 16, 64]), v=torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 16, 8]), k=torch.Size([1, 8, 16, 8]), v=torch.Size([1, 8, 16, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 16, 16]), mean: 1.4064269065856934, var: 64.0245361328125
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 16, 16]), sparsity: 0.8823
[DEBUG] RCIAttention: Output shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 0: After attention shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 0: After norm shape: torch.Size([1, 16, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 16, 64]), dps: 2.6
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4682, relu: 0.2347, fc2: 0.1902
[DEBUG] StretchFieldFFN: Using compression factor: 0.85
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 16, 64]), mean: 0.0000, var: 1.0010
[DEBUG] CVMPLayer 0: After FFN shape: torch.Size([1, 16, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 16, 64]), dps: 2.6
[DEBUG] RISL: Initializing previous state with shape torch.Size([1, 16, 64])
[DEBUG] RISL: Delta between current and previous: 0.0000, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 16, 64]), smoothing applied: False
[DEBUG] CVMPLayer 0: Output shape: torch.Size([1, 16, 64])
[DEBUG] After layer 0: shape=torch.Size([1, 16, 64]), mean=-0.0000, var=1.0010
[DEBUG] Processing layer 1
[DEBUG] CVMPLayer 1: Input shape: torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 16, 64]), k=torch.Size([1, 16, 64]), v=torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 16, 8]), k=torch.Size([1, 8, 16, 8]), v=torch.Size([1, 8, 16, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 16, 16]), mean: 0.029279988259077072, var: 0.015091408975422382
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 16, 16]), sparsity: 0.0908
[DEBUG] RCIAttention: Output shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 1: After attention shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 1: After norm shape: torch.Size([1, 16, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 16, 64]), dps: 2.6
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4673, relu: 0.2349, fc2: 0.1903
[DEBUG] StretchFieldFFN: Using compression factor: 0.85
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 16, 64]), mean: -0.0000, var: 1.0010
[DEBUG] CVMPLayer 1: After FFN shape: torch.Size([1, 16, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 16, 64]), dps: 2.6
[DEBUG] RISL: Initializing previous state with shape torch.Size([1, 16, 64])
[DEBUG] RISL: Delta between current and previous: 0.0000, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 16, 64]), smoothing applied: False
[DEBUG] CVMPLayer 1: Output shape: torch.Size([1, 16, 64])
[DEBUG] After layer 1: shape=torch.Size([1, 16, 64]), mean=0.0000, var=1.0010
[DEBUG] Final logits: shape=torch.Size([1, 16, 50000]), mean=0.0025, var=0.3397
[DEBUG] TierDrift: Tier changed from 6.2 to 4.2 (drift=2.0000), logits_var=0.3397, combined=2.3397
[DEBUG] Returning only logits

Testing with low tier...
[DEBUG] CVMPTransformer.forward: Input shape: torch.Size([1, 16]), mask: False
[DEBUG] ORCRouter: Starting routing with CVMPConfig(tier=2.5, dps=0.2, drift='Contained', frame=2, msc_verified=True)
[DEBUG] ORCRouter: Low tier route. Result: {'enable': ['LOG_BLEED', 'AETC'], 'suppress': '*'}
[DEBUG] Routing configuration: {'enable': ['LOG_BLEED', 'AETC'], 'suppress': '*'}
[DEBUG] Current healing state: 2
[DEBUG] BloomCatch: Logged tokens: [16481, 27007, 37544], buffer size: 8
[DEBUG] BloomCatch: TRIGGERED! Repeating sections at positions: [0, 1]
[DEBUG] Performing soft reset (healing_state: 2)
[DEBUG] Reset 0 parameters. Decreasing healing_state from 2 to 1
[DEBUG] Starting forward pass with input_ids shape: torch.Size([1, 16])
[DEBUG] After embedding: shape=torch.Size([1, 16, 64]), mean=0.0260, var=0.9976
[DEBUG] PositionalEncoding: Input shape: torch.Size([1, 16, 64])
[DEBUG] PositionalEncoding: Output shape: torch.Size([1, 16, 64])
[DEBUG] After positional encoding: shape=torch.Size([1, 16, 64]), mean=0.6585, var=64.2226
[DEBUG] Using tier_factor: 0.3164556962025316 (from tier=2.5)
[DEBUG] Processing layer 0
[DEBUG] CVMPLayer 0: Input shape: torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 16, 64]), k=torch.Size([1, 16, 64]), v=torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 16, 8]), k=torch.Size([1, 8, 16, 8]), v=torch.Size([1, 8, 16, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 16, 16]), mean: 0.48314446210861206, var: 8.37183666229248
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 16, 16]), sparsity: 0.6909
[DEBUG] RCIAttention: Output shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 0: After attention shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 0: After norm shape: torch.Size([1, 16, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4671, relu: 0.2340, fc2: 0.1913
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 16, 64]), mean: -0.0000, var: 1.0010
[DEBUG] CVMPLayer 0: After FFN shape: torch.Size([1, 16, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] RISL: Delta between current and previous: 0.3535, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 16, 64]), smoothing applied: False
[DEBUG] CVMPLayer 0: Output shape: torch.Size([1, 16, 64])
[DEBUG] After layer 0: shape=torch.Size([1, 16, 64]), mean=-0.0000, var=1.0010
[DEBUG] Processing layer 1
[DEBUG] CVMPLayer 1: Input shape: torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 16, 64]), k=torch.Size([1, 16, 64]), v=torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 16, 8]), k=torch.Size([1, 8, 16, 8]), v=torch.Size([1, 8, 16, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 16, 16]), mean: 0.0215185284614563, var: 0.00219280319288373
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 16, 16]), sparsity: 0.1094
[DEBUG] RCIAttention: Output shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 1: After attention shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 1: After norm shape: torch.Size([1, 16, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4691, relu: 0.2362, fc2: 0.1909
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 16, 64]), mean: 0.0000, var: 1.0010
[DEBUG] CVMPLayer 1: After FFN shape: torch.Size([1, 16, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] RISL: Delta between current and previous: 0.3888, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 16, 64]), smoothing applied: False
[DEBUG] CVMPLayer 1: Output shape: torch.Size([1, 16, 64])
[DEBUG] After layer 1: shape=torch.Size([1, 16, 64]), mean=-0.0000, var=1.0010
[DEBUG] Final logits: shape=torch.Size([1, 16, 50000]), mean=0.0030, var=0.3397
[DEBUG] TierDrift: Tier changed from 4.2 to 2.5 (drift=1.7000), logits_var=0.3397, combined=2.0397
[DEBUG] Returning only logits

--------------------------------------------------
Testing varying sequence lengths...
--------------------------------------------------

Processing sequence 1 of length 8...
[DEBUG] CVMPTransformer.forward: Input shape: torch.Size([1, 8]), mask: False
[DEBUG] ORCRouter: Starting routing with CVMPConfig(tier=2.5, dps=0.2, drift='Contained', frame=2, msc_verified=True)
[DEBUG] ORCRouter: Low tier route. Result: {'enable': ['LOG_BLEED', 'AETC'], 'suppress': '*'}
[DEBUG] Routing configuration: {'enable': ['LOG_BLEED', 'AETC'], 'suppress': '*'}
[DEBUG] Current healing state: 1
[DEBUG] BloomCatch: Logged tokens: [5631, 24807, 18399], buffer size: 9
[DEBUG] BloomCatch: TRIGGERED! Repeating sections at positions: [0]
[DEBUG] Performing soft reset (healing_state: 1)
[DEBUG] Reset 0 parameters. Decreasing healing_state from 1 to 0
[DEBUG] Starting forward pass with input_ids shape: torch.Size([1, 8])
[DEBUG] After embedding: shape=torch.Size([1, 8, 64]), mean=0.0380, var=0.9650
[DEBUG] PositionalEncoding: Input shape: torch.Size([1, 8, 64])
[DEBUG] PositionalEncoding: Output shape: torch.Size([1, 8, 64])
[DEBUG] After positional encoding: shape=torch.Size([1, 8, 64]), mean=0.7888, var=62.7159
[DEBUG] Using tier_factor: 0.3164556962025316 (from tier=2.5)
[DEBUG] Processing layer 0
[DEBUG] CVMPLayer 0: Input shape: torch.Size([1, 8, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 8, 64]), k=torch.Size([1, 8, 64]), v=torch.Size([1, 8, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 8, 8]), k=torch.Size([1, 8, 8, 8]), v=torch.Size([1, 8, 8, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 8, 8]), mean: 0.6065481901168823, var: 9.430456161499023
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 8, 8]), sparsity: 0.6074
[DEBUG] RCIAttention: Output shape: torch.Size([1, 8, 64])
[DEBUG] CVMPLayer 0: After attention shape: torch.Size([1, 8, 64])
[DEBUG] CVMPLayer 0: After norm shape: torch.Size([1, 8, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 8, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4648, relu: 0.2361, fc2: 0.1828
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 8, 64]), mean: -0.0000, var: 1.0019
[DEBUG] CVMPLayer 0: After FFN shape: torch.Size([1, 8, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 8, 64]), dps: 0.2
[DEBUG] RISL: Initializing previous state with shape torch.Size([1, 8, 64])
[DEBUG] RISL: Delta between current and previous: 0.0000, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 8, 64]), smoothing applied: False
[DEBUG] CVMPLayer 0: Output shape: torch.Size([1, 8, 64])
[DEBUG] After layer 0: shape=torch.Size([1, 8, 64]), mean=0.0000, var=1.0019
[DEBUG] Processing layer 1
[DEBUG] CVMPLayer 1: Input shape: torch.Size([1, 8, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 8, 64]), k=torch.Size([1, 8, 64]), v=torch.Size([1, 8, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 8, 8]), k=torch.Size([1, 8, 8, 8]), v=torch.Size([1, 8, 8, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 8, 8]), mean: 0.024244261905550957, var: 0.002249914687126875
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 8, 8]), sparsity: 0.0840
[DEBUG] RCIAttention: Output shape: torch.Size([1, 8, 64])
[DEBUG] CVMPLayer 1: After attention shape: torch.Size([1, 8, 64])
[DEBUG] CVMPLayer 1: After norm shape: torch.Size([1, 8, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 8, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4661, relu: 0.2368, fc2: 0.2104
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 8, 64]), mean: -0.0000, var: 1.0019
[DEBUG] CVMPLayer 1: After FFN shape: torch.Size([1, 8, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 8, 64]), dps: 0.2
[DEBUG] RISL: Initializing previous state with shape torch.Size([1, 8, 64])
[DEBUG] RISL: Delta between current and previous: 0.0000, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 8, 64]), smoothing applied: False
[DEBUG] CVMPLayer 1: Output shape: torch.Size([1, 8, 64])
[DEBUG] After layer 1: shape=torch.Size([1, 8, 64]), mean=0.0000, var=1.0019
[DEBUG] Final logits: shape=torch.Size([1, 8, 50000]), mean=-0.0004, var=0.3392
[DEBUG] TierDrift: Tier changed from 2.5 to 2.5 (drift=0.0000), logits_var=0.3392, combined=0.3392
[DEBUG] Returning only logits
Output shape: torch.Size([1, 8, 50000])

Processing sequence 2 of length 16...
[DEBUG] CVMPTransformer.forward: Input shape: torch.Size([1, 16]), mask: False
[DEBUG] ORCRouter: Starting routing with CVMPConfig(tier=2.5, dps=0.2, drift='Contained', frame=2, msc_verified=True)
[DEBUG] ORCRouter: Low tier route. Result: {'enable': ['LOG_BLEED', 'AETC'], 'suppress': '*'}
[DEBUG] Routing configuration: {'enable': ['LOG_BLEED', 'AETC'], 'suppress': '*'}
[DEBUG] Current healing state: 0
[DEBUG] BloomCatch: Logged tokens: [44275, 49793, 17469], buffer size: 10
[DEBUG] BloomCatch: No repetition detected in last 4 sections
[DEBUG] Starting forward pass with input_ids shape: torch.Size([1, 16])
[DEBUG] After embedding: shape=torch.Size([1, 16, 64]), mean=0.0158, var=1.0838
[DEBUG] PositionalEncoding: Input shape: torch.Size([1, 16, 64])
[DEBUG] PositionalEncoding: Output shape: torch.Size([1, 16, 64])
[DEBUG] After positional encoding: shape=torch.Size([1, 16, 64]), mean=0.5766, var=69.6161
[DEBUG] Using tier_factor: 0.3164556962025316 (from tier=2.5)
[DEBUG] Processing layer 0
[DEBUG] CVMPLayer 0: Input shape: torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 16, 64]), k=torch.Size([1, 16, 64]), v=torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 16, 8]), k=torch.Size([1, 8, 16, 8]), v=torch.Size([1, 8, 16, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 16, 16]), mean: 0.6149798631668091, var: 10.688056945800781
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 16, 16]), sparsity: 0.7310
[DEBUG] RCIAttention: Output shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 0: After attention shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 0: After norm shape: torch.Size([1, 16, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4630, relu: 0.2317, fc2: 0.1869
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 16, 64]), mean: -0.0000, var: 1.0010
[DEBUG] CVMPLayer 0: After FFN shape: torch.Size([1, 16, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] RISL: Initializing previous state with shape torch.Size([1, 16, 64])
[DEBUG] RISL: Delta between current and previous: 0.0000, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 16, 64]), smoothing applied: False
[DEBUG] CVMPLayer 0: Output shape: torch.Size([1, 16, 64])
[DEBUG] After layer 0: shape=torch.Size([1, 16, 64]), mean=-0.0000, var=1.0010
[DEBUG] Processing layer 1
[DEBUG] CVMPLayer 1: Input shape: torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 16, 64]), k=torch.Size([1, 16, 64]), v=torch.Size([1, 16, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 16, 8]), k=torch.Size([1, 8, 16, 8]), v=torch.Size([1, 8, 16, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 16, 16]), mean: 0.02340596728026867, var: 0.002413990208879113
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 16, 16]), sparsity: 0.0996
[DEBUG] RCIAttention: Output shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 1: After attention shape: torch.Size([1, 16, 64])
[DEBUG] CVMPLayer 1: After norm shape: torch.Size([1, 16, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4603, relu: 0.2313, fc2: 0.1984
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 16, 64]), mean: 0.0000, var: 1.0010
[DEBUG] CVMPLayer 1: After FFN shape: torch.Size([1, 16, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 16, 64]), dps: 0.2
[DEBUG] RISL: Initializing previous state with shape torch.Size([1, 16, 64])
[DEBUG] RISL: Delta between current and previous: 0.0000, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 16, 64]), smoothing applied: False
[DEBUG] CVMPLayer 1: Output shape: torch.Size([1, 16, 64])
[DEBUG] After layer 1: shape=torch.Size([1, 16, 64]), mean=0.0000, var=1.0010
[DEBUG] Final logits: shape=torch.Size([1, 16, 50000]), mean=0.0014, var=0.3377
[DEBUG] TierDrift: Tier changed from 2.5 to 2.5 (drift=0.0000), logits_var=0.3377, combined=0.3377
[DEBUG] Returning only logits
Output shape: torch.Size([1, 16, 50000])

Processing sequence 3 of length 32...
[DEBUG] CVMPTransformer.forward: Input shape: torch.Size([1, 32]), mask: False
[DEBUG] ORCRouter: Starting routing with CVMPConfig(tier=2.5, dps=0.2, drift='Contained', frame=2, msc_verified=True)
[DEBUG] ORCRouter: Low tier route. Result: {'enable': ['LOG_BLEED', 'AETC'], 'suppress': '*'}
[DEBUG] Routing configuration: {'enable': ['LOG_BLEED', 'AETC'], 'suppress': '*'}
[DEBUG] Current healing state: 0
[DEBUG] BloomCatch: Logged tokens: [49242, 21791, 7297], buffer size: 11
[DEBUG] BloomCatch: No repetition detected in last 4 sections
[DEBUG] Starting forward pass with input_ids shape: torch.Size([1, 32])
[DEBUG] After embedding: shape=torch.Size([1, 32, 64]), mean=-0.0212, var=0.9926
[DEBUG] PositionalEncoding: Input shape: torch.Size([1, 32, 64])
[DEBUG] PositionalEncoding: Output shape: torch.Size([1, 32, 64])
[DEBUG] After positional encoding: shape=torch.Size([1, 32, 64]), mean=0.2411, var=63.3870
[DEBUG] Using tier_factor: 0.3164556962025316 (from tier=2.5)
[DEBUG] Processing layer 0
[DEBUG] CVMPLayer 0: Input shape: torch.Size([1, 32, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 32, 64]), k=torch.Size([1, 32, 64]), v=torch.Size([1, 32, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 32, 8]), k=torch.Size([1, 8, 32, 8]), v=torch.Size([1, 8, 32, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 32, 32]), mean: 0.23528990149497986, var: 7.758697509765625
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 32, 32]), sparsity: 0.7661
[DEBUG] RCIAttention: Output shape: torch.Size([1, 32, 64])
[DEBUG] CVMPLayer 0: After attention shape: torch.Size([1, 32, 64])
[DEBUG] CVMPLayer 0: After norm shape: torch.Size([1, 32, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 32, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4652, relu: 0.2337, fc2: 0.1897
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 32, 64]), mean: 0.0000, var: 1.0005
[DEBUG] CVMPLayer 0: After FFN shape: torch.Size([1, 32, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 32, 64]), dps: 0.2
[DEBUG] RISL: Initializing previous state with shape torch.Size([1, 32, 64])
[DEBUG] RISL: Delta between current and previous: 0.0000, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 32, 64]), smoothing applied: False
[DEBUG] CVMPLayer 0: Output shape: torch.Size([1, 32, 64])
[DEBUG] After layer 0: shape=torch.Size([1, 32, 64]), mean=0.0000, var=1.0005
[DEBUG] Processing layer 1
[DEBUG] CVMPLayer 1: Input shape: torch.Size([1, 32, 64])
[DEBUG] RCIAttention: Input shapes: q=torch.Size([1, 32, 64]), k=torch.Size([1, 32, 64]), v=torch.Size([1, 32, 64])
[DEBUG] RCIAttention: Transformed shapes: qk=torch.Size([1, 8, 32, 8]), k=torch.Size([1, 8, 32, 8]), v=torch.Size([1, 8, 32, 8])
[DEBUG] RCIAttention: Score shape: torch.Size([1, 8, 32, 32]), mean: 0.016367027536034584, var: 0.0019213957712054253
[DEBUG] RCIAttention: Attention matrix shape: torch.Size([1, 8, 32, 32]), sparsity: 0.1010
[DEBUG] RCIAttention: Output shape: torch.Size([1, 32, 64])
[DEBUG] CVMPLayer 1: After attention shape: torch.Size([1, 32, 64])
[DEBUG] CVMPLayer 1: After norm shape: torch.Size([1, 32, 64])
[DEBUG] LogBleed: Not enough tokens to track (1 < 3)
[DEBUG] LogBleed: No penalty applied
[DEBUG] StretchFieldFFN: Input shape: torch.Size([1, 32, 64]), dps: 0.2
[DEBUG] StretchFieldFFN: Activation stats - fc1: 0.4653, relu: 0.2335, fc2: 0.1970
[DEBUG] StretchFieldFFN: Using compression factor: 1.0
[DEBUG] StretchFieldFFN: Output shape: torch.Size([1, 32, 64]), mean: 0.0000, var: 1.0005
[DEBUG] CVMPLayer 1: After FFN shape: torch.Size([1, 32, 64])
[DEBUG] RISL: Input shape: torch.Size([1, 32, 64]), dps: 0.2
[DEBUG] RISL: Initializing previous state with shape torch.Size([1, 32, 64])
[DEBUG] RISL: Delta between current and previous: 0.0000, threshold: 0.9
[DEBUG] RISL: Output shape: torch.Size([1, 32, 64]), smoothing applied: False
[DEBUG] CVMPLayer 1: Output shape: torch.Size([1, 32, 64])
[DEBUG] After layer 1: shape=torch.Size([1, 32, 64]), mean=0.0000, var=1.0005
[DEBUG] Final logits: shape=torch.Size([1, 32, 50000]), mean=0.0005, var=0.3382
[DEBUG] TierDrift: Tier changed from 2.5 to 2.5 (drift=0.0000), logits_var=0.3382, combined=0.3382
[DEBUG] Returning only logits
Output shape: torch.Size([1, 32, 50000])

==================================================
Demo complete!
==================================================
garret@garret:~/cvmp_transformer$ 


